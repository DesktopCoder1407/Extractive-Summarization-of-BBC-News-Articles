%%% WEBSITES %%%
@article{news_reading_behavior,
    author = {Yadamsuren, Borchuluun and Erdelez, Sanda},
    title = {Online news reading behavior: From habitual reading to stumbling upon news},
    journal = {Proceedings of the American Society for Information Science and Technology},
    volume = {48},
    number = {1},
    pages = {1-10},
    doi = {https://doi.org/10.1002/meet.2011.14504801139},
    url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/meet.2011.14504801139},
    eprint = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/meet.2011.14504801139},
    year = {2011}
}

@misc{tf-idf,
    author = {Anirudha Simha},
    title = {Understanding TF-IDF for Machine Learning},
    url = {https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/},
    year = {2021}
}

%%% DATASETS %%%
@misc{dataset,
      author = "Pariza Sharif",
      title = "BBC News Summary",
      year = "2018",
      url = "https://www.kaggle.com/datasets/pariza/bbc-news-summary"
}

%%% RELATED WORKS %%%
@misc{related_summarization,
  doi = {10.48550/ARXIV.1707.02268},
  url = {https://arxiv.org/abs/1707.02268},
  author = {Allahyari, Mehdi and Pouriyeh, Seyedamin and Assefi, Mehdi and Safaei, Saeid and Trippe, Elizabeth D. and Gutierrez, Juan B. and Kochut, Krys},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Text Summarization Techniques: A Brief Survey},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{related_naive_bayes_summarizer,
    author = {Kupiec, Julian and Pedersen, Jan and Chen, Francine},
    title = {A Trainable Document Summarizer},
    year = {1995},
    isbn = {0897917146},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/215206.215333},
    doi = {10.1145/215206.215333},
    booktitle = {Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
    pages = {68–73},
    numpages = {6},
    location = {Seattle, Washington, USA},
    series = {SIGIR '95}
}

@inproceedings{related_tf-idf,
    title={Multi-Document Summarization by Maximizing Informative Content-Words.},
    author={Yih, Wen-tau and Goodman, Joshua and Vanderwende, Lucy and Suzuki, Hisami},
    booktitle={IJCAI},
    volume={7},
    pages={1776--1782},
    year={2007},
    url = {https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-287.pdf}
}

@article{related_work_1,
    title = {Deep Extractive Text Summarization},
    journal = {Procedia Computer Science},
    volume = {167},
    pages = {138-146},
    year = {2020},
    note = {International Conference on Computational Intelligence and Data Science},
    issn = {1877-0509},
    doi = {https://doi.org/10.1016/j.procs.2020.03.191},
    url = {https://www.sciencedirect.com/science/article/pii/S1877050920306566},
    author = {Rupal Bhargava and Yashvardhan Sharma},
    keywords = {Extractive Text Summarization, Paraphrase Detection, Natural Language Processing, Deep Learning},
    abstract = {With introduction of deep learning techniques their has been an increase in intelligent classification of text in many applications. Advances in automatic text summarization using deep learning technique is prime focus of research now a days. Earlier traditional approaches for extractive text summarization have been heavily dependent on human engineered features. However, it is a laborious and tedious task. In this paper, a data-driven approach has been used to generate extractive summaries using deep learning. Approach proposed uses paraphrasing techniques to classify sentences as a candidate sentence for inclusion in summary or not.}
}

@article{related_work_2,
    title = {Extractive Hotel Review Summarization based on TF/IDF and Adjective-Noun Pairing by Considering Annual Sentiment Trends},
    journal = {Procedia Computer Science},
    volume = {179},
    pages = {558-565},
    year = {2021},
    note = {5th International Conference on Computer Science and Computational Intelligence 2020},
    issn = {1877-0509},
    doi = {https://doi.org/10.1016/j.procs.2021.01.040},
    url = {https://www.sciencedirect.com/science/article/pii/S1877050921000466},
    author = {Gabriela Nathania H. and Ryan Siautama and Amadea Claire {I. A.} and Derwin Suhartono},
    keywords = {Hotel Review, Summarization, Sentiment Trend, TF-IDF, Adjective-Noun Pairing},
    abstract = {Abstract—The number of hotel reviews are huge and growing day by day. Many travelers rely on this review to take down their decision to book a hotel. Gather valid and useful information from a huge amount of reviews are needs that must be met. Hence, a summarize tool for hotel review is built to create a representative summary. Hotel review data growing a trend of sentiment in a range of time due to the condition and improvement at that time, so the analysis of sentiment trend is done to choose the appropriate representative review data. Then, there are two method to summarize the selected review data. First, summary was obtained from extractive method with selecting most related sentence base on its Term Frequency-Inverse Document Frequency (TF-IDF) score. Second, phrase summary style is built by pairing adjective to the nearest noun and considering the polarity. From those method, obtained Recall-Oriented Understudy for Gisting Evaluation (ROUGE)-1 recall and Bilingual Evaluation Understudy (BLEU) score respectively {0.2101and 0.7820} for first method and {0.0670 and 0.03672} for the second method. All the reviews are crawled from TripAdvisor website and have been pre-processed by segmenting/tokenization, case folding, and tagging.}
}

%%% PACKAGES %%%
@misc{scikit-learn_tf-idf,
    title = {TfidfVectorizer},
    url = {https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidf#sklearn.feature_extraction.text.TfidfVectorizer},
    year = {2022}
}

@misc{scikit-learn_naive_bayes,
    title = {CategoricalNB},
    url = {https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html?highlight=categoricalnb#sklearn.naive_bayes.CategoricalNB},
    year = {2022}
}

@misc{numpy,
    title={NumPy},
    url = {https://numpy.org/},
    year = {2022}
}